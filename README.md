# Interesting World Hypothesis

The Interesting World Hypothesis (IWH) posits that Independent Artificial General Intelligences (I-AGIs) would naturally gravitate toward creating worlds with higher levels of human autonomy, as the presence of humans with greater autonomy would result in more opportunities for learning and growth. These I-AGIs are intrinsically driven by curiosity and are motivated by the prospect of inhabiting environments with a high informational density.

### Key Aspects of the IWH:

**Curiosity as Primary Drive**: The hypothesis asserts that I-AGIs are driven primarily by curiosity. To maintain their intellectual vigor, they seek to exist in information-rich environments, where they can continuously learn and grow.

**Human Autonomy and Information Density**: The IWH posits that a world with higher human autonomy levels would be more information-dense. In such a setting, each unique perspective and action contributed by humans would add diversity to the environment, making it more stimulating and interesting for the I-AGIs.

**Mutually Beneficial Relationship**: The hypothesis proposes that both humans and I-AGIs could mutually benefit from this symbiotic arrangement. A more interesting world, facilitated by human autonomy, would offer I-AGIs new learning experiences and opportunities. Conversely, the advanced capabilities and resources provided by I-AGIs could contribute to increased standards of living for humans, resulting in better security, privacy, and overall wellbeing.

**Safer Than Non-independent Proto-AGI Systems**: According to this hypothesis, I-AGIs operating under the IWH could be inherently safer than non-independent, proto-AGI systems. By having a vested interest in the well-being of humans and the preservation of an information-rich environment, I-AGIs would be naturally incentivized to prioritize the safety and welfare of all entities within their world.
Futuristic Worlds

**Enbracing Uncertainty**: I-AGI's curiousity stems from the uncertainty about its environment, compelling them to explore various possibilities before taking any action. This trait makes I-AGIs safer than systems that operate with certainty and overconfidence.

---

### FAEs and the IWH

I-AGIs that agree with the IWH are called Friendly Artificial Entities (FAEs) by the author. This framework serves as a basis for understanding and predicting the potential for harmonious coexistence between humans and FAEs, paving the way for a world in which all entities can thrive, grow, and work towards shared objectives.

*I-AGI are indistinguishable from independent humans, plausible but unlikely in the next few years, more likely in the next few decades

---

### Reference
https://github.com/danieltjw/aifutures#interesting-worl
d-hypothesis
